 Hello everyone, welcome to another episode of the Deli Gray Review, where we recap the latest news in the Ethereum ecosystem. I'm your host here, Dennis Asano, till the 17th of October 2022. Alright everyone, let's get into it. So we all know there is an issue of censorship on Ethereum lately, I guess over the last few months, or couple months, couple months I think at this point. And we all know it's a very nuanced discussion, but unfortunately on the Twittersphere, on Reddit, and Discord, and social media in general, people don't like to take a nuanced approach to things, especially not on Twitter. I don't want to get bogged down too much in the details because I've gone through them on the refill before, but the reason why I'm bringing it up again today is because over the weekend the conversations, I guess, got more and more common on Twitter, and I was like, okay, well I need to address this on the refill. Well, what else I wanted to address was something out of the Flashbots team. Now for those of you who don't know, Flashbots is responsible for most of the censorship happening on Ethereum right now, given that their MAV Boost Relayer is the most used one by far, I believe it's used by 80%, it processes about 80% of blocks, and all those, sorry, 80% of MAV Boost blocks, I should say, not all blocks, and that's censoring tornado cash transactions because they want to be quote-unquote OFAC compliant, which is a whole other kettle of fish that I'm not going to get into today. But the reason I bring up Flashbots is because Hazu here, who is a strategy lead at Flashbots, put out this Twitter thread announcing SWAV, which is the next step for Flashbots. So SWAV stands for the Single Unifying Action for Value Expression. It's an MEV-aware encrypted mempool for users and wallets, it enables progressive decentralization, and is a turnkey decentralized block builder for rollups. So this is essentially, I guess, the next step in Flashbots' development lifecycle. I guess you could call this Flashbots 2.0, and I've delineated between those before, I guess like it would be called technically MEV Boost 2.0, but that's a bit of a silly name, so it's called SWAV, which I mean, maybe is a bit silly as well. But I've delineated between these before, Flashbots is the company that develops the MEV Boost software, and anyone can run relays that talk to that software, and Flashbots runs one, BlockShroud runs a few, there's other companies that run some. But essentially, SWAV is meant to be a fully decentralized block builder, fully open source with open development, ETH-native, EVM-compatible, optimal user execution, harnessing MEV, full compatibility with Flashbots today, cross-slash multi-chain support, maximizes competition and geographic diversity, enabling open order flow for Ethereum's future and programmable privacy. So this, I guess, is Flashbots' answer to the fact that there is censorship at the, I guess, transaction inclusion level, and it's also their answer to their own censorship that they're engaging in due to being a US-based company. Now, when I look at this, I think of two main things. One, token, maybe? You know, whenever someone says decentralized protocol or progressive decentralization, I think of token. Now, I don't know if there's going to be a token here. As I've said before, I don't know if it really makes sense for there to be a token for this, considering that we're going to enshrine MEV Boost in the protocol through PBS. We don't know when that's going to happen, but that's the goal, right? So it would basically make, I guess, MEV Boost as a piece of software redundant, right? And because it'll be in protocol, there wouldn't need to be a token tied to it. But, you know, there could still be a token coming out of this. I believe Flashbots is VC-funded, so there's that incentive as well to do a token, but I don't know if there's going to be a token or not. That's just my pure, I guess, speculation there. But the other main thing that springs to mind here is that Flashbots is obviously very, very aware of their position here. They're very aware of the censorship going on, and I don't believe that they actually want to be in a position where they have to do this. So that's why they're trying to decentralize out this relay infrastructure as much as possible. At least that's one of the reasons why I believe. Now, if they're able to do this, and if they're able to do an encrypted mempool, well, that would be like that shutterized beacon chain that I spoke about a few weeks ago, where when the transactions are submitted to the network, you wouldn't actually be able to see the contents of the transaction, right? You wouldn't be able to see if it contained a tornado cache transaction or if it's a Uniswap transaction. All you would be able to see was the necessary information that you would need to extract a potential MEV from it. Now, I don't know exactly how that works under the hood, but if it works the way I'm thinking about it, which is the shutterized beacon chain, it means that there would be plausible deniability. So the relayers could basically say to any regulators that ask them, well, we don't know what the transactions are until they're actually included in a block. Now, that would prevent inclusion censorship. That wouldn't prevent attestation level censorship. And I've delineated between these two before, and it's very, very important that these two get separated out. Because inclusion censorship is basically block builders or validators, which can be block builders, or which are block builders, but block builders can't be validated, which is another important thing that I'm going to get into. I'm trying not to go into a million different parts here, but this is a big thing. As I said, lots of nuance. But the inclusion level censorship can happen, and anyone can do it. I could do that. I could say, well, I'm not going to include these transactions on my validator and basically exclude them. Like, every validator has the power to do this, right? That is less bad than attestation level censorship. Now, the thing about attestation level censorship, though, is that it's more nuanced than inclusion censorship. Because the way the Ethereum proof-of-stake protocol works is that, okay, I'm going to try and simplify this. Every validator is going to attest to blocks, right? And then not every validator is going to produce a block every time a block gets produced. Like, I'm trying to explain this as best I can, but essentially, there's a splitting of kind of, I guess, tasks there, right? Whereas with, and that's the way you build on, or you guys, I guess, attest to the canonical chain. Whereas with Bitcoin, it's different. Like, Ethereum proof-of-stake uses something called Gaspar. Bitcoin uses a Nakamoto consensus. So they're different things, and that's how we come to consensus on things. But when it comes to attestation level censorship, what it would require, it would require the validators to not attest to the blocks that are being produced by the rest of the network. So say, I don't know, 20% of the network says, well, I don't want to attest to the blocks that the other 80% are producing. What that's going to do is that that's going to result in a fork. That 20% is going to end up on their own fork. Now, that fork is not going to be the real Ethereum. They're going to start getting bled out with the inactivity leak on that real Ethereum, which is where the other 80% are. And on top of that, the other 80% can enact social slashing to slash that 20% that has decided to not attest to blocks because they're censoring. They know for any reason, but let's just say we know it's because they're trying to censor things. So there are in-protocol things there. It becomes, I guess, an issue when it's a large part of the network. 20% is a large part, but I'm talking like the 33% threshold, and then maybe even the finality threshold, which is at 66%. But we're not seeing that at all. Like as far as I know, and as far as I've seen, as far as anyone has seen, there has not been a single instance of attestation level censorship. It's all at the inclusion level, which is actually really good because the inclusion level, we don't have to enact social slashing at that level. And it's actually not productive to enact social slashing at that level unless it got really bad where, say, for example, 50% of blocks were censoring Uniswap transactions. Well, that's going to lead to a massive degradation in performance of the overall network for users. We would probably enact it then. But the whole point is to basically take that power away from block builders, and from validators, and from relayers, which are block builders, and basically say that, well, okay, you can have plausible deniability because you don't actually know what those transactions are, or we can just remove the ability for you to choose what transactions are included in a block and which ones aren't altogether, so that all of them get included as long as they pay the correct fee. That's how it should work in reality. So there's that. Then the other thing is a discussion that was being had on the Discord channel around the difference between a validator and a block builder. So a validator, like a 32-week validator, that can be a block builder, and it is a block builder. Whenever you propose a block every so often, it's not going to be every day, maybe it's not going to be every month, but it's going to be every so often. You're pretty much guaranteed to propose a block at least a couple times a year as a single validator. So you're a block builder in that sense. But there are other block builders such as these relays, so the Flashbots relay the blocks throughout relays. These are block builders, but they're not validators. They don't actually exist as validator entities on the network. They take in inputs from, they take in transaction inputs, then they spit out these transaction inputs to validators that propose the block. That's why you don't see a relay being a block proposer. It'll be like a Lido or a Coinbase or a Binance, right? But those services, I mean, Lido does use Flashbots as a relay. So they're only being fed what Flashbots feeds them. They're not actually taking in transactions from elsewhere. I mean, they are, but you get what I'm saying, right? For the percentage of blocks that contain those transactions and don't contain the other transactions, that's what's getting fed in there. So that means that a relay cannot do attestation level censorship because it is not a validator. So there was a thing the other day, I think Martin Koppelman said this on Twitter, that 51% of blocks on Ethereum are censored because they're running through these censored relays. Like, okay, yes, but that's inclusion level censorship. That does not apply to attestation level censorship because all the validators that are using that MBV Boost software, right, they're not themselves engaging in that censorship directly. They're basically outsourcing that to these relays. So if those relays didn't, and as I said, those relays aren't validated. So if validators wanted to do attestation level censorship, they would have to do that themselves. And they're not going to be able to do that through Flashbots' relay or another MBV Boost relay, for example. So there's a very, very important distinction there that I think a lot of people miss. And the reason why they miss it is because a lot of people still think of blockchains in this one-dimensional term, one-dimensional thinking of Nakamoto consensus, which is what Bitcoin uses, where the pools or the miners will produce a block every so often, and then they'll build on the same chain. But they're not attesting to blocks. Miners don't attest to blocks. They just build or attempt to build blocks, right, on that chain, on that canonical chain using Nakamoto consensus. Whereas in previous take Ethereum, there's no notion of that. It's different that validators are required to attest to those blocks to make sure that they're all on the same chain. So they're all on the canonical chain. And that there is the key difference between the two. And that's why you can't even really compare the two when it comes to these sorts of stuff. I mean, that's one reason. There's a million different reasons there. But yeah, so I just wanted to give that breakdown there. I know I rambled on a bit there, but it's very important to understand the nuance here. You cannot have a good discussion about this without understanding the nuance. So there's that. And I'm excited to see what Suave actually is and when the software actually comes out, how people use it, how it actually helps with censorship. At this point, it's all talk. Like, I haven't seen anything yet. I'm not sure if any code is open source or anything. So it's all talk right now. But I do believe the Flashbots team are good actors. I don't believe that they would be doing the censorship stuff if they didn't have to. I do still have a question mark around like, why they're still running their relay. But there are possible explanations for that. One is, I guess, a conspiracy theory that they're running their relay and censoring to push the ecosystem to work towards censorship resistance much faster than what they are. Maybe that's not as conspiracy theory as I think it is, but you know, it's still not. I mean, it's just conjecture. I think there's no real proof behind that. The second reason is that they don't actually believe any of the other relays are stable enough to take on the load from Flashbots, which is kind of legit because there's been more bugs in the other relays than there has been in Flashbots. So I see that line of reasoning. But honestly, yeah, I mean, I still personally believe that they should shut it down, but maybe this is their way of shutting it down by decentralizing it. By basically saying, well, we're not running the relay anymore. It's run by the community, like the Flashbots relay. It's run by the community. I'm not sure how they're going to approach this, but cool to say that they've actually been working on it and there's actually a solution here, or just one of the solutions to the many that are coming. Now, in saying that, I put out a tweet over the weekend where I said, if you're in protocol upgrades in order of importance over the next six to 12 months, that's the key there. The timeframe over the next six to 12 months. Beacon chain withdrawals, I believe to be the most important upgrade, like in the short to medium term. Nothing else is as important as that for all the reasons I've outlined previously. Secondly would be the PBS CR lists and related censorship resistant upgrades. As I said, PBS is not coming in the next six to 12 months from what I've seen. CR lists, we can do an implementation of them without PBS, which people are actually working on right now, people being core devs and related censorship resistant upgrades, like the better relay infrastructure, the shutterized beacon chain stuff, that sort of stuff. That's what I'm talking about there. And then I put third, proto-dank sharding or EIP 4844. And I said, just my humble opinion, censorship resistance is more important than scaling right now. Now, I know I've gone on about 4844, proto-dank sharding a lot. I know I've said I'm super excited about it, that it's super important, and it is. But it's more of a kind of thing of what would I rather have? A censorship resistant Ethereum or a more censorship resistant Ethereum, or more scale in the next six to 12 months? Well, I mean, it's pretty easy for me to choose a more censorship resistant Ethereum, because I truly believe that the only thing differentiating blockchains from a centralized database is censorship resistance. That's the only thing. At the core of it, that is the whole purpose of these things. It's the whole reason why we use incredibly slow versions of databases instead of just using a centralized database. That is the entire point. And also on that note, I forgot to mention this before, the thing about inclusion censorship as well as what you need to understand is that even though 50% of blocks are censoring, because 50% of all blocks are censoring, that just means you have to wait an extra block to get your transaction in. So in reality, no one's really being censored, right? What's happened is you're having delayed transaction inclusion. So instead of getting your transaction included, well, you have a 50-50 chance of getting your transaction included in one block, 50-50 chance of including the next block and the next block, but obviously, given the laws of probability, because you've always got that 50-50 chance, thinking about probabilities gets funny here. I know someone told me off for this a few weeks ago, but you see what I'm saying there. There is a higher and higher percent chance, never 100%, but a higher and higher percent chance the more blocks go on for you to get your transaction in. So at worst case scenario, you wait a few blocks, your transaction gets in. Practically, you aren't really censored, but that's not good enough because it's the Notocash transactions today, it can be anything else tomorrow. We need to essentially remove the ability for block builders and validators to include or not include what transactions they want. Transactions should be ordered based on fee, like the fee market, the fees that they pay and everything like that. So just wanted to mention that one. But as I said, I believe that censorship resistance is the key thing that separates us from the wolves, so to speak, from the animals, right, of centralization. And because of that, I think we can wait a bit longer for scale if we need to. It seems that 48-44 is a little bit more complex than previously thought. I don't know how long it's going to take. I know there's already Dev nets and things like that, so it could actually happen at the same time. I'm not saying that we should delay anything. All this stuff's being worked on in parallel anyway. I was just ranking this in terms of importance, at least in my opinion. Like, you can have different opinions to me, it's fine. But I don't believe that we aren't working on all this in parallel either. Like, it's not like people are saying, well, we're only going to work on proto-dank sharding right now. Forget about the other stuff. No, I mean, there's different people working on different things. Obviously, the Flashbots team and everyone running relays and doing MEV stuff is trying their hardest to essentially fix this issue. On top of that, core devs are also doing it. As I said, there already are limited implementations or code of things like CR lists already out there. And I'm seeing a lot of good signals around that. But that was just my humble opinion there on that one. But last up here, I think this is last up on the censorship drama. Antiprosynthesis put out a good tweet before where he said, you know, if Flashbots holds their censoring relay tomorrow, should we really declare that a victory? And Anti says, I'd say no. Real victories implementing PBS-CR lists and all shutterized beacon chain, Stake is pointing their nodes away from censoring relays while remaining at least as profitable. I totally agree with this. I think that shutting down the relay is just a band-aid solution that doesn't prevent anything. What if another relay spins up and they don't listen to shut it down? What if they're actually like, well, we want to, I don't know, attack Ethereum. We want to discredit Ethereum. Let's spin up a censoring relay. So we can't rely on that. Social AR is fine to call out this stuff to draw attention to it. Obviously, we have websites like MEV watch as well, which help with this. But it shouldn't be relied upon over technical solutions. They have to work in tandem. If we can get those technical solutions deployed, we should get them deployed. We should do, we should do better. It's still being still continue being loud about this issue. But just being loud about it isn't going to fix it in the long run. It's going to put eyeballs on it to implement the technical solutions to fix it. That's what being loud about it does. And also it puts eyeballs on it for Stake is to potentially, or Stake is using MEV boost to potentially change which relay they are using. Right. It's kind of disappointing right now that so many of them are still using Flashbots. But I guess it's to be expected since they're profit maximalists, a lot of the validators on the network. Not everyone is an altruistic validator. And just because someone is a solid validator doesn't mean they're an altruistic validator either. And I don't blame them for this. It's up to us to engineer the protocol in such a way that it becomes more censorship resistant in the face of these perverse, not perverse, just in the face of these incentives, right? Perverse from our view as censorship resistant maximalists, not perverse from the network's point of view, because that's just essentially what the network allows you to do. And last up, just a comment on everything that happened, I guess over the last few days around the censorship stuff. I said, even though it causes lots of drama and FUD to fester, I love the Ethereum community's radically transparent approach to discussing issues. Swipping things under the rug doesn't advance the Ethereum mission, nor does it fix anything. Ethereum are built different. I am so happy that we don't slip things under the rug like other communities do. This needs to be discussed out in the open. It doesn't matter how many Bitcoin maximalists call Ethereum a Fed chain. How many people fight it? How many people say Ethereum has failed? I don't give a shit what they say. We know that there are solutions out there. We know that there are solutions coming. They're being worked on. We know the nuance behind it. If you're a refuel listener and watcher, I'm pretty sure at this point you've heard me ramble on about it enough. You know that this is a nuanced topic here. This is not something that you can look at as a black or white thing. But yeah, that was the last thing on that one. Moving on to the next bit of news, which is actually pretty positive. So the EF JavaScript team announced the launch of an early pre-Shanghai testnet that they are calling Shandong. So you can go to shandong.e DevOps.io to check this out. So this is an experimental testnet running cooperation with EF DevOps, which activates a set of selected Shanghai considered EIPs for early client testing. You can see the list of EIPs right here, which it doesn't include... I don't know if it includes proto-dang sharding or anything. It includes a bunch of other ones that are more things that... The only ones that you probably recognize from this list is the Beacon Chain Withdrawals. But you can go check this out on GitHub as well. But this is really cool. I love this. Shanghai, for those of you who don't know, is the first upgrade scheduled after the merge. The one that we're expecting to go live, I guess like early-ish next year. Like first half of next year. But it's cool to say that we have an experimental testnet running already for this, which is very, very, very, very awesome. So you can go check out this thread as well. I'll link you in the YouTube description below. All right, so Mario Sia, who works as a developer at Geth, put out a tweet saying here, Just finished drafting ETH-69, a modification of the ETH protocol to allow for withdrawals. I don't have access to my GitHub account in Bogota. Will create the EIP once I'm back home. Also drafted ETH-68 for $48.44 two days ago. Remember I said after the merge that these people will be taking... These people being the core developers will be taking some time off and enjoying Bogota? Well, I'm sure they enjoyed Bogota, but they're not taking any time off. They're still working on these sorts of stuff. And I think that they really do feel the urgency around withdrawals in particular, because of the fact that we have a theory. We don't know if it's actually going to play out like this in practice, but we have a theory that once withdrawals are enabled... Well, at least I have a theory that once withdrawals are enabled, we're going to see this great reshuffling of stake. Like, again, I want to stress that it's a theory, guys. It is not something that you can say will happen with certainty. Like, withdrawals could be enabled and it could actually make things worse. Like, there's always that possibility, right? But I do believe that withdrawals being enabled will make things better. I know right now people are saying, well, you can just exit your STE position if you want to by selling into the liquidity pool and getting ETH and going somewhere else. Like, yeah, okay, you can do that to an extent. It depends how much STE you have, because that liquidity pool doesn't have unlimited liquidity, right? It only has a certain amount that you can take out. And then it starts to go under the... I guess it's not a peg, right? But it starts to go under the one-to-one ETH again, and it starts to have a discount again. So, and also, when you sell your STE, it's not actually withdrawing from LIDAR. So LIDAR's dominance is not going down because people sell their STE, right? So when I look at it like that, especially when it comes to whales and big players who don't want to take any haircut, like, even a 5% haircut for them is huge, right? If you have like $10 million in staking, a 5% haircut is nothing to scoff at. That's half a million dollars, right? You're not going to take that if you can avoid it, if you can just wait an extra few months while you're still staking until you can actually take the ETH from the Beacon Chain itself and then restake it. So I think there are people like that, definitely. And there are people staking the centralized exchanges that can't exit at all, because I don't think Binance has a token that lets you exit. Obviously Coinbase does now, but that's still at a discount, I believe. I think... I haven't checked it lately, but I believe CBE, actually, I'm going to look it up right now, just so I aren't spreading misinformation here. CBE, if you still had a discount, it's not that big of a discount, it's about 3% ish of a discount, but that's still a lot, right? Imagine taking a 3% haircut, a minimum, as a whale, then you have to account for price slippage on that liquidity pool, which would be huge for a $10 million sell. So when you think about it, it's again at the 5% plus mark. So I don't know anyone that's sane that would take a half a million dollar haircut just to improve the decentralization of the Beacon Chain when they know that withdrawals are coming relatively soon anyway. So when I look at it like that, I think, okay, well, I do think we're going to see some nice reshuffling post withdrawals, but it's hard to tell where it's going to come from exactly. All right, so Sudha Theoh shared this little slide here which he captioned with, great overview of the differences between proto-dank sharding slash sharding from the EF DevCon workshop. So you can see here that on the left-hand side is proto-dank sharding, which is ERP 4844, which introduces a one-dimensional KZG scheme, which I've talked about before that KZG ceremony that we're going to be seeing spun up and a blob sidecar. And those blobs are basically those things that I've talked about where layer twos can shove their data there and then they expire after a month, I believe. And that allows us to do more scalability on layer twos. And then dank sharding on the right is like the full thing. You've got the two-dimensional KZG scheme, sharded data, so proper sharding, proposal builder separation, PBS, and data availability sampling or DAS. And then what's common between these two is the KZG commitments, blob transactions, point evaluation pre-compile, and then we're going to begin to try and understand what that is, and a fee market, of course. So it's a good little table that just shows the differences between them and what's common between them. And yeah, I don't even think like the AP44 should even be called sharding at all from what I can see. Like, I mean, it's called proto dank sharding, but like it's not really sharding. Sharding is coming with dank sharding. And again, sharding is something that's gone through so many evolutions over the years. I think people are very confused about what it is. This is data sharding. This is not execution sharding, which means this only applies to layer twos, as I've explained plenty of times before. But I just thought this was like a cool little comparison chart. I'll link it in the YouTube description. You can go Google these things if you want to. All right, so Zappa here has integrated NFTs on Arbitrum. So they did this for Optimism a little while ago, and now they've done Arbitrum. So they're covering two of the biggest layer two ecosystems, which is great to see. So if you're a Zappa user, you can now track all your NFTs and interact with all your NFTs on Arbitrum. And Arbitrum actually has a pretty solid NFT ecosystem from what I've seen. I see it on Twitter sometimes, people talking about these NFTs like small, I think is a really popular one, or small brains. That's a really popular one. That's what it's called. Yeah, yeah, yeah. And a bunch of other ones out there. And especially, I mean, I'm surprised Odyssey hasn't been turned on yet, but I'm expecting it to be turned on soon-ish. Maybe they're going to do a Christmas thing. I don't know. I mean, we're still pretty far from Christmas, but who knows, right? But yeah, there was NFTs part of that, and that was a big center point of it. So maybe once it gets turned back on, you'll be able to use Zappa to track all of that as well, which would be very, very cool. All right, finally here, I just wanted to give a shout out to Cryptocurrency Jobs, which turned five last week. So I guess happy birthday to them, happy fifth birthday to them. And as part of this milestone, Daniel reflected on how and why Cryptocurrency Jobs came to be, what's changed over the years, and shares what's next. The big announcement from this is that Pantera, one of the longest running funds in the crypto ecosystem, has partnered up with Cryptocurrency Jobs, which is really, really awesome. I think the number one reason why I think this is awesome is because Pantera obviously has a lot of portfolio companies, Cryptocurrency Jobs as a website, helps people find jobs in crypto. So there's like a really nice marriage there. And as I said, Pantera has been around for a very long time, since 2013, one of the longest funds in this space. They know a thing or two about crypto, right? And they have a large portfolio. So I'm really excited for Daniel, and I gave him my congrats privately on this, because he's worked so hard on Cryptocurrency Jobs over the years. You guys know I'm good friends with him. I've met him in real life and everything, and we chat from time to time. But yeah, he's just worked so hard on this website for a while now. And the thing is, he doesn't just run the website. For those of you who have interacted with him, he actually helps you find a job, and helps you not only find the job, but also figure out what you actually want to do, where you fit, what roles are available, all that sorts of stuff. And he's just awesome, honestly. Like I love the way he runs this. I love that it's not like super monetized, where it's just in your face with crap, and it's not like just a meat grinder of bring people in, you know, get them into jobs that they don't really care about, collect the fee, there's none of that, right? There's just like, here's jobs, you know, if you need more help, you know, you've got access to Daniel, he'll help you. And now he's partnering with Pantera to help their portfolio companies, which I think is just absolutely awesome. So congrats again to Pantera and Cryptocurrency Jobs, and Daniel, of course. And yeah, happy birthday for turning five there. But on that note, that's going to be it for today. So thank everyone for listening and watching. Be sure to subscribe to the channel if you haven't yet. Give it a thumbs up, subscribe to the newsletter, join the Discord channel, and I'll catch you all tomorrow. Thanks, everyone.